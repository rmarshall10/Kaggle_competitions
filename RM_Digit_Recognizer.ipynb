{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport numpy as np\nfrom keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, MaxPool2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/digit-recognizer/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n\ntrain.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":3,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 42000 entries, 0 to 41999\nColumns: 785 entries, label to pixel783\ndtypes: int64(785)\nmemory usage: 251.5 MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train['label']\nX_train = train.drop('label', axis=1)\nX_train.head()\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make pixel values a max of 1\nX_train = X_train/255\ntest = test/255","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(test.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"(42000, 784)\n(28000, 784)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#covert each picture to 28x28 array to use CNN\nX_train = X_train.values\ntest = test.values","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape(-1,28,28,1)\ntest = test.reshape(-1,28,28,1)\n\nprint(X_train.shape)\nprint(test.shape)","execution_count":8,"outputs":[{"output_type":"stream","text":"(42000, 28, 28, 1)\n(28000, 28, 28, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"imshow(X_train[44][:,:,0])","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f2a0311ae80>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make y values one hot encoded\n\ndef convert_to_one_hot(Y, C):\n    Y = np.eye(C)[Y.reshape(-1)].T\n    return Y.T\n\ny_train = convert_to_one_hot(y_train.values, 10)\ny_train.shape","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"(42000, 10)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state = 1, test_size = 0.05)\n","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation = \"softmax\"))","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\nmodel.compile(optimizer = optimizer,\n              loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x=X_train, y=y_train, epochs=5, batch_size=128)","execution_count":14,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n39900/39900 [==============================] - 118s 3ms/step - loss: 0.2576 - accuracy: 0.9161\nEpoch 2/5\n39900/39900 [==============================] - 116s 3ms/step - loss: 0.0677 - accuracy: 0.9794\nEpoch 3/5\n39900/39900 [==============================] - 118s 3ms/step - loss: 0.0528 - accuracy: 0.9842\nEpoch 4/5\n39900/39900 [==============================] - 120s 3ms/step - loss: 0.0419 - accuracy: 0.9866\nEpoch 5/5\n39900/39900 [==============================] - 119s 3ms/step - loss: 0.0373 - accuracy: 0.9883\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f29d7000b38>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the model\nmodel.save('RM_Digit_Recognizer_model.h5')\n\n# Recreate the exact same model purely from the file\n#new_model = keras.models.load_model('RM_Digit_Recognizer_model.h5')","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_classes(X_val)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val = np.argmax(y_val, axis=1)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\n\nprint(classification_report(y_val,predictions))\nprint(confusion_matrix(y_val,predictions))","execution_count":18,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       210\n           1       0.99      1.00      0.99       250\n           2       0.97      0.98      0.98       234\n           3       0.96      1.00      0.98       204\n           4       1.00      0.97      0.98       207\n           5       0.99      0.99      0.99       200\n           6       1.00      0.99      0.99       186\n           7       1.00      0.97      0.99       189\n           8       1.00      0.99      1.00       205\n           9       0.97      1.00      0.98       215\n\n    accuracy                           0.99      2100\n   macro avg       0.99      0.99      0.99      2100\nweighted avg       0.99      0.99      0.99      2100\n\n[[210   0   0   0   0   0   0   0   0   0]\n [  0 249   1   0   0   0   0   0   0   0]\n [  0   0 229   5   0   0   0   0   0   0]\n [  0   0   0 203   0   0   0   0   0   1]\n [  0   1   1   0 200   0   0   0   0   5]\n [  0   0   1   1   0 198   0   0   0   0]\n [  0   0   0   0   1   1 184   0   0   0]\n [  0   0   3   2   0   0   0 184   0   0]\n [  0   2   0   0   0   0   0   0 203   0]\n [  0   0   0   0   0   1   0   0   0 214]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_test = model.predict_classes(test)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_test = pd.DataFrame(predictions_test)\nindices = pd.DataFrame(np.arange(1,len(predictions_test)+1))\npredictions_submit = pd.concat([indices, predictions_test], axis = 1)\npredictions_submit.columns = ['ImageId', 'Label']\npredictions_submit.to_csv('submission.csv', index=False)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}